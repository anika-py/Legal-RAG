{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAmnogug15my"
      },
      "outputs": [],
      "source": [
        "!pip install sentence-transformers pinecone tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "EsqQJs4k7Nd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_FILE = \"/content/drive/MyDrive/judgments_chunks.jsonl\"\n",
        "INDEX_NAME = \"legal-landmark-cases\"\n",
        "LANDMARK_YEARS = [1973,1978,2018,2024,1992, 1994, 1997, 2014, 2017, 2023]\n",
        "PINECONE_API_KEY = \"\"\n",
        "PINECONE_ENV = \"gcp-starter\"\n",
        "DIMENSION = 384\n",
        "BATCH_SIZE = 100"
      ],
      "metadata": {
        "id": "fZRNboJt7NZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "id": "61zTiufd8O4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Pinecone client\n",
        "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
        "\n",
        "# Create index if it doesn't exist\n",
        "if INDEX_NAME not in [index.name for index in pc.list_indexes()]:\n",
        "    pc.create_index(\n",
        "        name=INDEX_NAME,\n",
        "        dimension=DIMENSION,\n",
        "        metric=\"cosine\",\n",
        "        spec=ServerlessSpec(\n",
        "            cloud=\"aws\",\n",
        "            region=\"us-east-1\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "# Connect to index\n",
        "index = pc.Index(INDEX_NAME)"
      ],
      "metadata": {
        "id": "lHkkJYyB8TrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = pc.Index(INDEX_NAME)\n",
        "print(\"Index stats:\", index.describe_index_stats())"
      ],
      "metadata": {
        "id": "3LZeqsyk_s4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectors = []\n",
        "total_uploaded = 0\n",
        "year_counts = {year: 0 for year in LANDMARK_YEARS}\n",
        "upload_failed = False\n",
        "\n",
        "with open(INPUT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
        "    total_lines = sum(1 for _ in f)\n",
        "\n",
        "print(f\"Processing {total_lines} lines from JSONL...\")\n",
        "\n",
        "with open(INPUT_FILE, \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in tqdm(f, total=total_lines, desc=\"Uploading chunks\"):\n",
        "        if line.strip():\n",
        "            case = json.loads(line)\n",
        "            year = int(case.get(\"date_of_judgment\", \"\")[:4])\n",
        "\n",
        "            if year in LANDMARK_YEARS:\n",
        "                text = case[\"chunk_text\"]\n",
        "                embedding = model.encode(text).tolist()\n",
        "\n",
        "                vectors.append({\n",
        "                    \"id\": case[\"chunk_id\"],\n",
        "                    \"values\": embedding,\n",
        "                    \"metadata\": {\n",
        "                        \"case_title\": case.get(\"case_title\", \"\"),\n",
        "                        \"year\": year,\n",
        "                        \"citation\": case.get(\"citation\", \"\"),\n",
        "                        \"bench\": \", \".join(case.get(\"bench\", [])),\n",
        "                        \"bench_strength\": case.get(\"bench_strength\", 0),\n",
        "                        \"article_references\": case.get(\"article_references\", []),\n",
        "                        \"source_pdf\": case.get(\"source_pdf\", \"\")\n",
        "                    }\n",
        "                })\n",
        "\n",
        "                year_counts[year] += 1\n",
        "\n",
        "                # Upload in batches\n",
        "                if len(vectors) == BATCH_SIZE:\n",
        "                    try:\n",
        "                        index.upsert(vectors=vectors)\n",
        "                        total_uploaded += len(vectors)\n",
        "                        vectors = []\n",
        "                    except Exception as e:\n",
        "                        print(f\"\\n❌ Upload failed: {e}\")\n",
        "                        print(\"Stopping further uploads (likely Pinecone limit reached).\")\n",
        "                        upload_failed = True\n",
        "                        break\n",
        "\n",
        "    # Upload any remaining vectors\n",
        "    if not upload_failed and vectors:\n",
        "        try:\n",
        "            index.upsert(vectors=vectors)\n",
        "            total_uploaded += len(vectors)\n",
        "        except Exception as e:\n",
        "            print(f\"\\n❌ Final upload failed: {e}\")\n",
        "            upload_failed = True\n",
        "\n",
        "print(f\"\\n✅ Upload complete! Total uploaded before error: {total_uploaded}\")\n",
        "print(\"\\nYear-wise counts:\")\n",
        "for y, count in year_counts.items():\n",
        "    print(f\"{y}: {count} chunks\")"
      ],
      "metadata": {
        "id": "SoX5gdcD-yQe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}